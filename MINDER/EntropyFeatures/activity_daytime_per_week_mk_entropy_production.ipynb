{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dcarte\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from numpy import log2\n",
    "from argparse import Namespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from misc.sampler import CartesianSampler\n",
    "from toy.ratchet import simulation, ep_per_step, analytic_etpy\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "warnings.filterwarnings('ignore')\n",
    "dcarte.domains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 0  # daytime:0 (6:00-18:00), night:1 (18:00-6:00)\n",
    "timestep = 0  # per day: 0, per week: 1, per hour: 2, accurate time: 3\n",
    "activity_raw = dcarte.load('Activity','RAW')\n",
    "activity_legacy = dcarte.load('Motion','LEGACY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw(activity_raw):\n",
    "    \n",
    "    # delete\n",
    "    activity = activity_raw\n",
    "    \n",
    "    # revise location names\n",
    "    activity = activity.copy()\n",
    "    mapping = {\n",
    "    'conservatory':'conservatory',\n",
    "    'WC1':'wc',\n",
    "    'corridor1':'corridor',\n",
    "    'living room':'living',\n",
    "    'study':'study',\n",
    "    'dining room':'dining',\n",
    "    'bathroom1':'bathroom',\n",
    "    'bedroom1':'bedroom',\n",
    "    'hallway':'hallway',\n",
    "    'lounge':'lounge',\n",
    "    'kitchen':'kitchen',\n",
    "    'cellar':'cellar',\n",
    "    'office':'office'\n",
    "    }\n",
    "    activity.location_name = activity.location_name.map(mapping)\n",
    "    activity = activity[~activity['location_name'].isin(['cellar','office','dining','study','living','corridor','wc','conservatory'])]\n",
    "    activity.location_name = activity.location_name.values.astype('str')\n",
    "    activity.patient_id = activity.patient_id.values.astype('str')\n",
    "    \n",
    "    # delete rebundant columns\n",
    "    activity.drop(['home_id','location_id','source'],axis=1, inplace=True)\n",
    "    \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_legacy(activity_raw):\n",
    "    \n",
    "    # delete\n",
    "    activity = activity_raw\n",
    "    \n",
    "    # revise location names\n",
    "    activity = activity.copy()\n",
    "    mapping = {\n",
    "    'Hallway':'hallway',\n",
    "    'Kitchen':'kitchen',\n",
    "    'Study':'study',\n",
    "    'Bathroom':'bathroom',\n",
    "    'Lounge':'lounge',\n",
    "    'Bedroom':'bedroom',\n",
    "    'Living Room':'living',\n",
    "    'Front Door':'door',\n",
    "    'D':'d',\n",
    "    'Dining Room':'dining',\n",
    "    }\n",
    "    activity.location_name = activity.location_name.map(mapping)\n",
    "    activity = activity[~activity['location_name'].isin(['study','living','door','d','dining'])]\n",
    "    activity.location_name = activity.location_name.values.astype('str')\n",
    "    activity.patient_id = activity.patient_id.values.astype('str')\n",
    "    \n",
    "    # delete rebundant columns\n",
    "    activity.drop(['index','timezone'],axis=1, inplace=True)\n",
    "    activity = activity[['start_date','patient_id','location_name']]\n",
    "    \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_daytime_night(my_activity,my_time):\n",
    "    \n",
    "    # daytime:0 (6:00-18:00), night:1 (18:00-6:00)\n",
    "    signal = my_time\n",
    "    \n",
    "    if signal==0:\n",
    "        print(\"Time: daytime\")\n",
    "        activity_day = my_activity\n",
    "        activity_day['hour'] = activity_day.start_date.dt.hour\n",
    "        # choose daytime, between [6:00-18:00]\n",
    "        activity_day = activity_day[activity_day['hour'].between(6,17)]\n",
    "        activity_day = activity_day.copy()\n",
    "        activity_day.drop(['hour'],axis=1, inplace=True)\n",
    "        activity_day['day_date'] =  activity_day.start_date.values.astype(\"datetime64[D]\")\n",
    "        activity_select = activity_day\n",
    "        \n",
    "    elif signal==1:\n",
    "        print(\"Time: night\")\n",
    "        activity_night = my_activity\n",
    "        activity_night['hour'] = activity_night.start_date.dt.hour\n",
    "        # choose night time, except [6:00-18:00]. e.g., the night time on 22/3 includes 18:00-24:00 on 22/3 and 00:00-06:00 on 23/3\n",
    "        activity_night = activity_night[~activity_night['hour'].between(6,17)]\n",
    "        activity_night = activity_night.copy()\n",
    "        activity_night['day_date'] = activity_night.start_date.values.astype(\"datetime64[D]\")\n",
    "        activity_night['last_date'] = activity_night['start_date'] + pd.Timedelta(days=-1)\n",
    "        activity_night['day_date'] =  activity_night['day_date'].mask(activity_night['hour']<6, activity_night['last_date'])\n",
    "        activity_night['day_date'] = activity_night.day_date.values.astype(\"datetime64[D]\")\n",
    "        activity_night.drop(['hour','last_date'],axis=1, inplace=True)\n",
    "        activity_select = activity_night\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Error: please input correct number! daytime:0 (6:00-18:00), night:1 (18:00-6:00)\")\n",
    "        \n",
    "    return activity_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_time_step(my_activity, my_timestep):\n",
    "    \n",
    "    activity = pd.DataFrame(my_activity)\n",
    "    # per day: 0, per week: 1, per hour: 2, accurate time: 3\n",
    "    signal = my_timestep\n",
    "    \n",
    "    if signal==0:\n",
    "        print(\"Timestep: per day\")\n",
    "        activity.day_date = activity.day_date.values.astype(\"datetime64[D]\")\n",
    "        activity = activity.groupby(['patient_id','day_date']).filter(lambda x:len(x)>2)\n",
    "        \n",
    "    elif signal==1:\n",
    "        print(\"Timestep: per week\")\n",
    "        activity['week'] = activity['day_date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "        activity.drop(['day_date','start_date'],axis=1, inplace=True)\n",
    "        activity.columns=['patient_id','location_name','start_date']\n",
    "        activity = activity.groupby(['patient_id','start_date']).filter(lambda x:len(x)>2)\n",
    "        \n",
    "    elif signal==2:\n",
    "        print(\"Timestep: per hour\")\n",
    "        activity.start_date = activity.start_date.values.astype(\"datetime64[h]\")\n",
    "    \n",
    "    elif signal==3:\n",
    "        print(\"Accurate time\")\n",
    "        activity.start_date = activity.start_date.values.astype(\"datetime64[ns]\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Error: please input correct number! per day: 0, per week: 1\")\n",
    "    \n",
    "    return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class NEEP(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(NEEP, self).__init__()\n",
    "        self.encoder = nn.Embedding(opt.n_token, opt.n_hidden)\n",
    "        self.h = nn.Sequential()\n",
    "        for i in range(opt.n_layer):\n",
    "            self.h.add_module(\n",
    "                'fc%d' % (i+1), nn.Linear(2*opt.n_hidden, 2*opt.n_hidden))\n",
    "            self.h.add_module(\n",
    "                'relu%d' % (i+1), nn.ReLU())\n",
    "        self.h.add_module(\n",
    "            'out', nn.Linear(2*opt.n_hidden, 1))\n",
    "\n",
    "    def forward(self, s1, s2):\n",
    "        s1 = self.encoder(s1)\n",
    "        s2 = self.encoder(s2)\n",
    "        x = torch.cat([s1, s2], dim=-1)\n",
    "        _x = torch.cat([s2, s1], dim=-1)\n",
    "        return self.h(x) - self.h(_x)\n",
    "\n",
    "\n",
    "# define training and validation function\n",
    "def train(opt, model, optim, trajs, sampler):\n",
    "    model.train()\n",
    "    batch, next_batch = next(sampler)\n",
    "\n",
    "    s_prev = trajs[batch].to(opt.device)\n",
    "    s_next = trajs[next_batch].to(opt.device)\n",
    "    ent_production = model(s_prev, s_next)\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    # The objective function J. Equation (2)\n",
    "    loss = (-ent_production + torch.exp(-ent_production)-1).mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def validate(opt, model, trajs, sampler):\n",
    "    model.eval()\n",
    "\n",
    "    ret = []\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, next_batch in sampler:\n",
    "            s_prev = trajs[batch].to(opt.device)\n",
    "            s_next = trajs[next_batch].to(opt.device)\n",
    "            \n",
    "            ent_production = model(s_prev, s_next)\n",
    "            entropy = ent_production.cpu().squeeze().numpy()\n",
    "            ret.append(entropy)\n",
    "            loss += (- ent_production + torch.exp(-ent_production)-1).sum().cpu().item()\n",
    "    loss = loss / sampler.size\n",
    "    ret = np.concatenate(ret)\n",
    "    ret = ret.reshape(trajs.shape[0], trajs.shape[1]-1)\n",
    "    return ret, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16 weeks for training, training timestep = 16 weeks, testing timestep = one week\n",
    "def get_entropy_production(my_data):\n",
    "    \n",
    "    print(my_data.patient_id.iloc[1])\n",
    "    # define training and testing data\n",
    "    train_data = my_data[my_data['week_rank']<=16]\n",
    "    trajs = np.array([(my_data[my_data['week_rank']<=16]).location_name]) # 16 weeks for training, the rest for testing\n",
    "\n",
    "    # define parameters\n",
    "    opt = Namespace()\n",
    "    opt.device = 'cpu' \n",
    "    opt.n_token = 5\n",
    "    opt.n_hidden = 32\n",
    "    opt.n_layer = 1\n",
    "    opt.batch_size = len(trajs[0])\n",
    "    # opt.batch_size = 5\n",
    "    opt.lr = 0.05\n",
    "    # opt.lr = 0.01\n",
    "    opt.wd = 5e-5\n",
    "\n",
    "    opt.record_freq = 500\n",
    "    opt.seed = 398\n",
    "\n",
    "    torch.manual_seed(opt.seed)\n",
    "\n",
    "    opt.M = len(trajs)             # number of trajectories\n",
    "    opt.L = len(trajs[0])       # lenth of a trjectory \n",
    "\n",
    "    trajs_t = torch.from_numpy(trajs).long().view(1,-1,1)\n",
    "\n",
    "    # training\n",
    "    model = NEEP(opt)\n",
    "    model = model.to(opt.device)\n",
    "    optim = torch.optim.Adam(model.parameters(), opt.lr, weight_decay=opt.wd)\n",
    "\n",
    "    train_sampler = CartesianSampler(opt.M, opt.L, opt.batch_size, device=opt.device)\n",
    "\n",
    "    opt.n_iter = 100 # number of train ing iteration\n",
    "\n",
    "    losses = []\n",
    "    for i in tqdm(range(1, opt.n_iter + 1)):\n",
    "        loss = train(opt, model, optim, trajs_t, train_sampler)\n",
    "        if i%5==0:\n",
    "            losses.append(loss)\n",
    "    \n",
    "    # testing\n",
    "    prediction = pd.DataFrame(columns=['week', 'entropy_production'])\n",
    "    my_week_date = []\n",
    "    my_prediction = []\n",
    "    test_data = my_data # take all of the data as the testing data\n",
    "    for m in range(len(test_data.week_rank.unique())):\n",
    "        my_week = test_data[test_data['week_rank']==m+1] # set the timestep of testing data to one week\n",
    "        week_date = (np.array((test_data[test_data['week_rank']==m+1]).week))[0]\n",
    "        week_result = []\n",
    "        for mm in range(len(my_week.day_rank.unique())):\n",
    "            test_trajs = np.array([(my_week[my_week['day_rank']==mm+1]).location_name])\n",
    "\n",
    "            opt.M_t = len(test_trajs)  \n",
    "            opt.L_t = len(test_trajs[0])\n",
    "            opt.test_batch_size = len(test_trajs[0])\n",
    "\n",
    "            test_trajs_t = torch.from_numpy(test_trajs).long().view(1,-1,1)\n",
    "            test_sampler = CartesianSampler(opt.M_t, opt.L_t, opt.test_batch_size, device=opt.device, train=False)\n",
    "\n",
    "            if (len(test_trajs[0])>10):\n",
    "                pred, _ = validate(opt, model, test_trajs_t, test_sampler)\n",
    "                pred = pred.flatten()\n",
    "                cum_pred = np.cumsum(pred)\n",
    "\n",
    "                slope, _, _, _, _ = stats.linregress(range(len(cum_pred)), cum_pred)\n",
    "                week_result.append(slope)\n",
    "        \n",
    "\n",
    "        my_week_date.append(week_date)\n",
    "        my_prediction.append(np.array(week_result).mean())\n",
    "\n",
    "    prediction['entropy_production'] = my_prediction\n",
    "    prediction['week'] = my_week_date\n",
    "    prediction = prediction.reset_index(drop=True)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_legacy = pre_process_legacy(activity_legacy)\n",
    "activity_raw = pre_process_raw(activity_raw)\n",
    "activity = pd.concat([activity_raw, activity_legacy], axis=0)\n",
    "\n",
    "activity = select_daytime_night(activity, time)\n",
    "activity = select_time_step(activity,timestep)\n",
    "activity = activity.sort_values(['patient_id','day_date'])\n",
    "activity = activity.reset_index(drop=True)\n",
    "\n",
    "# revise location names\n",
    "activity = activity.copy()\n",
    "mapping = {\n",
    "'bathroom':'0',\n",
    "'bedroom':'1',\n",
    "'hallway':'2',\n",
    "'lounge':'3',\n",
    "'kitchen':'4',\n",
    "}\n",
    "activity.location_name = activity.location_name.map(mapping)\n",
    "activity.location_name = activity.location_name.values.astype('int')\n",
    "activity['week'] = activity['day_date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "\n",
    "week_num = activity.groupby([activity['patient_id']]).apply(lambda x: len(x.week.unique()))\n",
    "week_num.to_csv('middle.csv')\n",
    "week_num = pd.read_csv('middle.csv')\n",
    "week_num.columns = ['patient_id','week_num']\n",
    "\n",
    "activity = pd.merge(activity,week_num,on='patient_id')\n",
    "\n",
    "activity = activity[activity['week_num']>16] # at least 16 weeks for training\n",
    "activity.drop(['week_num'],axis=1, inplace=True)\n",
    "activity = activity.sort_values(['patient_id','day_date'])\n",
    "activity = activity.reset_index(drop=True)\n",
    "activity['week_rank'] = activity.groupby('patient_id')['week'].rank(method='dense')\n",
    "activity.start_date = activity.start_date.values.astype('datetime64[D]')\n",
    "activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity['day_rank'] = activity.groupby([activity['patient_id'], activity['week']])['day_date'].rank(method='dense')\n",
    "activity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(activity.patient_id.unique()))\n",
    "etp = activity.groupby([activity['patient_id']]).apply(get_entropy_production)\n",
    "etp.to_csv('middle.csv')\n",
    "etp = pd.DataFrame(pd.read_csv('middle.csv'), columns = ['patient_id','week','entropy_production'])\n",
    "etp = etp.groupby(['patient_id']).filter(lambda x:len(x)>8)\n",
    "etp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etp.to_csv('c_activity_daytime_per_week_entropy_production.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42db6f1feb5be9d95545c2a7b7395325c381e86fa288f14274020ac1bf67e557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
