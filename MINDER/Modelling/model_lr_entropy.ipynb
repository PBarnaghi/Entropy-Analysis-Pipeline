{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lr_all_events(my_dataset_symptoms):\n",
    "\n",
    "    dataset_symptoms = shuffle(my_dataset_symptoms).reset_index(drop=True) # disrupt the order\n",
    "    \n",
    "    # split training dataset and test dataset\n",
    "    X = dataset_symptoms.iloc[:, :-1]\n",
    "    Y = dataset_symptoms.iloc[:, -1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)\n",
    "\n",
    "    # normalisation\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    standardized_X_train = X_scaler.transform(X_train)\n",
    "    standardized_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "    # Initialising the model and training\n",
    "    log_reg = linear_model.LogisticRegression(penalty='l2', C=0.0001, solver='sag', class_weight = 'balanced',random_state=10)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # prediction and results\n",
    "    pred_test = log_reg.predict_proba(standardized_X_test)\n",
    "    pred_train = log_reg.predict(standardized_X_train)\n",
    "    pred_test = log_reg.predict(standardized_X_test)\n",
    "\n",
    "    train_recall = recall_score(y_train, pred_train, average=\"binary\")\n",
    "    train_f1 = f1_score(y_train, pred_train, average='binary')\n",
    "    test_recall = recall_score(y_test, pred_test,average=\"binary\")\n",
    "    test_f1 = f1_score(y_test, pred_test, average='binary')\n",
    "    train_acc = accuracy_score(y_train, pred_train)\n",
    "    test_acc = accuracy_score(y_test, pred_test)\n",
    "\n",
    "    # prediction and results\n",
    "    pred_test = log_reg.predict_proba(standardized_X_test)\n",
    "    pred_train = log_reg.predict(standardized_X_train)\n",
    "    pred_test = log_reg.predict(standardized_X_test)\n",
    "\n",
    "    train_recall = recall_score(y_train, pred_train, average=\"binary\")\n",
    "    train_f1 = f1_score(y_train, pred_train, average='binary')\n",
    "    test_recall = recall_score(y_test, pred_test,average=\"binary\")\n",
    "    test_f1 = f1_score(y_test, pred_test, average='binary')\n",
    "    train_acc = accuracy_score(y_train, pred_train)\n",
    "    test_acc = accuracy_score(y_test, pred_test)\n",
    "\n",
    "    # Compute the predicted probabilities of the positive class\n",
    "    probs = log_reg.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Compute the TPR and FPR for various threshold values\n",
    "    fpr, tpr, thresholds = roc_curve(Y, probs)\n",
    "\n",
    "    auc_data = pd.DataFrame([fpr, tpr]).T\n",
    "    auc_data.columns = ['fpr','tpr']\n",
    "    auc_data.to_csv('auc_entropy_LR.csv')\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return train_recall, test_recall, train_f1, test_f1, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_BASELINE = os.path.join('dataset_entropy_measures_all_events.csv')\n",
    "dataset_baseline = pd.read_csv(DATA_DIR_BASELINE)\n",
    "dataset_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing dataset\n",
    "dataset_all_events = pd.DataFrame(dataset_baseline, columns=dataset_baseline.columns[1:])\n",
    "dataset_all_events_positive = dataset_all_events[(dataset_all_events.disturbed_sleep_pattern == 1) | (dataset_all_events.agitation_irritability_aggression == 1) | (dataset_all_events.depressed_anxiety == 1)| (dataset_all_events.accidental_fall == 1)| (dataset_all_events.motor_function_behavior == 1)| (dataset_all_events.period_of_confusion == 1)| (dataset_all_events.hospital == 1)| (dataset_all_events.uti == 1)]\n",
    "dataset_all_events_positive['label']=1\n",
    "dataset_all_events = pd.merge(dataset_all_events, dataset_all_events_positive, how='left')\n",
    "dataset_all_events.label = dataset_all_events.label.fillna(0.5)\n",
    "dataset_all_events = pd.DataFrame(dataset_all_events, columns=['patient_id', 'day_date','entropy_daytime','entropy_night','entropy_rate_mk_daytime','entropy_rate_mk_night','entropy_production_daytime','entropy_production_night','entropy_vn_frequency_daytime','entropy_vn_frequency_night','entropy_vn_duration_daytime','entropy_vn_duration_night','duration_difference_daytime','duration_difference_night','label'])\n",
    "dataset_all_events = dataset_all_events.dropna()\n",
    "dataset_all_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and test, logic regression\n",
    "train_recall_lr = []\n",
    "test_recall_lr = []\n",
    "train_f1_lr = []\n",
    "test_f1_lr = []\n",
    "train_acc_lr = []\n",
    "test_acc_lr = []\n",
    "for i in range(30):\n",
    "\n",
    "    # # balance negative and positive lables\n",
    "    dataset_num = dataset_all_events.label.value_counts().min()\n",
    "    dataset_symptoms_negative = dataset_all_events[dataset_all_events['label']==0.5].sample(dataset_num)\n",
    "    dataset_symptoms_positive = dataset_all_events[dataset_all_events['label']==1.0].sample(dataset_num)\n",
    "    dataset_symptoms = pd.concat([dataset_symptoms_negative, dataset_symptoms_positive])\n",
    "    dataset_symptoms = pd.DataFrame(dataset_symptoms, columns=['entropy_daytime','entropy_night','entropy_rate_mk_daytime','entropy_rate_mk_night','entropy_production_daytime','entropy_production_night','entropy_vn_frequency_daytime','entropy_vn_frequency_night','entropy_vn_duration_daytime','entropy_vn_duration_night','duration_difference_daytime','duration_difference_night','label'])\n",
    "\n",
    "    # optimise the format of the labels\n",
    "    mapping = {0.5:0, 1.0:1}\n",
    "    dataset_symptoms['label'] = dataset_symptoms['label'].map(mapping)\n",
    "\n",
    "    train_recall_lr_i, test_recall_lr_i, train_f1_lr_i, test_f1_lr_i, train_acc_lr_i, test_acc_lr_i = apply_lr_all_events(dataset_symptoms)\n",
    "    \n",
    "    train_recall_lr.append(train_recall_lr_i)\n",
    "    test_recall_lr.append(test_recall_lr_i)\n",
    "    train_f1_lr.append(train_f1_lr_i)\n",
    "    test_f1_lr.append(test_f1_lr_i)\n",
    "    train_acc_lr.append(train_acc_lr_i)\n",
    "    test_acc_lr.append(test_acc_lr_i)\n",
    "\n",
    "train_recall_lr = pd.DataFrame(train_recall_lr, columns=['train_recall'])\n",
    "test_recall_lr = pd.DataFrame(test_recall_lr, columns=['test_recall'])\n",
    "train_f1_lr = pd.DataFrame(train_f1_lr, columns=['train_f1'])\n",
    "test_f1_lr = pd.DataFrame(test_f1_lr, columns = ['test_f1'])\n",
    "train_acc_lr = pd.DataFrame(train_acc_lr, columns=['train_acc'])\n",
    "test_acc_lr = pd.DataFrame(test_acc_lr, columns=['test_acc'])\n",
    "\n",
    "\n",
    "all_events_recall_lr = pd.concat([train_recall_lr, test_recall_lr, train_f1_lr, test_f1_lr, train_acc_lr, test_acc_lr],axis=1)\n",
    "# all_events_recall_logic_reg.to_csv('evaluation_entropy_LR.csv')\n",
    "all_events_recall_lr.boxplot()  \n",
    "plt.ylim(0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_events_recall_logic_reg.to_csv('n_evaluation_entropy_LR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63db258f63f9026914af4dc973048ad77a8a8d707001bf6ff07195bd565e7307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
