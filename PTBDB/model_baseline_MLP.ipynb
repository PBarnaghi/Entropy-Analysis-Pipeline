{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.svm import SVC\n",
    "# from xgboost import XGBClassifier\n",
    "from matplotlib import colors \n",
    "from matplotlib.ticker import PercentFormatter \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932233</td>\n",
       "      <td>0.869679</td>\n",
       "      <td>0.886186</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.908775</td>\n",
       "      <td>0.933970</td>\n",
       "      <td>0.801043</td>\n",
       "      <td>0.749783</td>\n",
       "      <td>0.687229</td>\n",
       "      <td>0.635100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606941</td>\n",
       "      <td>0.384181</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.223567</td>\n",
       "      <td>0.276836</td>\n",
       "      <td>0.253430</td>\n",
       "      <td>0.184826</td>\n",
       "      <td>0.153349</td>\n",
       "      <td>0.121872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.923963</td>\n",
       "      <td>0.853303</td>\n",
       "      <td>0.791859</td>\n",
       "      <td>0.734255</td>\n",
       "      <td>0.672043</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.670507</td>\n",
       "      <td>0.667435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.899261</td>\n",
       "      <td>0.230129</td>\n",
       "      <td>0.032348</td>\n",
       "      <td>0.142329</td>\n",
       "      <td>0.223660</td>\n",
       "      <td>0.328096</td>\n",
       "      <td>0.367837</td>\n",
       "      <td>0.381701</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.935618</td>\n",
       "      <td>0.801661</td>\n",
       "      <td>0.805815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722741</td>\n",
       "      <td>0.480789</td>\n",
       "      <td>0.454829</td>\n",
       "      <td>0.319834</td>\n",
       "      <td>0.266874</td>\n",
       "      <td>0.308411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.932233  0.869679  0.886186  0.929626  0.908775  0.933970  0.801043   \n",
       "1  1.000000  0.606941  0.384181  0.254237  0.223567  0.276836  0.253430   \n",
       "2  1.000000  0.951613  0.923963  0.853303  0.791859  0.734255  0.672043   \n",
       "3  0.977819  0.899261  0.230129  0.032348  0.142329  0.223660  0.328096   \n",
       "4  0.935618  0.801661  0.805815  1.000000  0.722741  0.480789  0.454829   \n",
       "\n",
       "        7         8         9    ...  177  178  179  180  181  182  183  184  \\\n",
       "0  0.749783  0.687229  0.635100  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.184826  0.153349  0.121872  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.685100  0.670507  0.667435  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.367837  0.381701  0.389094  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.319834  0.266874  0.308411  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   185  186  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal = pd.read_csv(\"ptbdb_abnormal.csv\", header = None) \n",
    "normal = pd.read_csv(\"ptbdb_normal.csv\", header = None)\n",
    "\n",
    "abnormal = abnormal.drop([187], axis=1)\n",
    "normal = normal.drop([187], axis=1)\n",
    "\n",
    "abnormal['label'] = 1\n",
    "normal['label'] = 0\n",
    "\n",
    "dataset_all = pd.concat([abnormal, normal], sort=True).reset_index(drop=True)\n",
    "dataset_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                12032     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,642\n",
      "Trainable params: 24,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 19:08:44.093748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.093831: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.093881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.093928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.093973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.094017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.094061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.094105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-10 19:08:44.094120: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-10 19:08:44.094453: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 13ms/step - loss: 0.5987 - accuracy: 0.6737 - val_loss: 0.5435 - val_accuracy: 0.7276\n",
      "Epoch 2/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.7958 - val_loss: 0.4492 - val_accuracy: 0.7980\n",
      "Epoch 3/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8299 - val_loss: 0.4264 - val_accuracy: 0.8091\n",
      "Epoch 4/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8409 - val_loss: 0.4112 - val_accuracy: 0.8116\n",
      "Epoch 5/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8463 - val_loss: 0.4029 - val_accuracy: 0.8159\n",
      "Epoch 6/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3370 - accuracy: 0.8597 - val_loss: 0.3867 - val_accuracy: 0.8246\n",
      "Epoch 7/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.3239 - accuracy: 0.8636 - val_loss: 0.3628 - val_accuracy: 0.8419\n",
      "Epoch 8/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2981 - accuracy: 0.8781 - val_loss: 0.3309 - val_accuracy: 0.8573\n",
      "Epoch 9/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2721 - accuracy: 0.8931 - val_loss: 0.3905 - val_accuracy: 0.8295\n",
      "Epoch 10/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.8949 - val_loss: 0.3228 - val_accuracy: 0.8592\n",
      "Epoch 11/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2413 - accuracy: 0.9055 - val_loss: 0.2828 - val_accuracy: 0.8771\n",
      "Epoch 12/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2120 - accuracy: 0.9215 - val_loss: 0.3128 - val_accuracy: 0.8715\n",
      "Epoch 13/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.2017 - accuracy: 0.9243 - val_loss: 0.2898 - val_accuracy: 0.8882\n",
      "Epoch 14/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1948 - accuracy: 0.9257 - val_loss: 0.2542 - val_accuracy: 0.8962\n",
      "Epoch 15/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1757 - accuracy: 0.9360 - val_loss: 0.2573 - val_accuracy: 0.8993\n",
      "Epoch 16/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1626 - accuracy: 0.9411 - val_loss: 0.2562 - val_accuracy: 0.8950\n",
      "Epoch 17/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1550 - accuracy: 0.9414 - val_loss: 0.2509 - val_accuracy: 0.9024\n",
      "Epoch 18/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9410 - val_loss: 0.2434 - val_accuracy: 0.9117\n",
      "Epoch 19/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 0.9397 - val_loss: 0.2412 - val_accuracy: 0.9148\n",
      "Epoch 20/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1389 - accuracy: 0.9473 - val_loss: 0.2319 - val_accuracy: 0.9172\n",
      "Epoch 21/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1233 - accuracy: 0.9580 - val_loss: 0.2441 - val_accuracy: 0.9141\n",
      "Epoch 22/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.9518 - val_loss: 0.2263 - val_accuracy: 0.9228\n",
      "Epoch 23/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1169 - accuracy: 0.9572 - val_loss: 0.2275 - val_accuracy: 0.9086\n",
      "Epoch 24/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1064 - accuracy: 0.9626 - val_loss: 0.2267 - val_accuracy: 0.9228\n",
      "Epoch 25/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.1060 - accuracy: 0.9606 - val_loss: 0.2705 - val_accuracy: 0.9104\n",
      "Epoch 26/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0982 - accuracy: 0.9623 - val_loss: 0.2546 - val_accuracy: 0.9129\n",
      "Epoch 27/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0998 - accuracy: 0.9631 - val_loss: 0.2634 - val_accuracy: 0.8993\n",
      "Epoch 28/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0987 - accuracy: 0.9628 - val_loss: 0.2325 - val_accuracy: 0.9141\n",
      "Epoch 29/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.2373 - val_accuracy: 0.9197\n",
      "Epoch 30/30\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9708 - val_loss: 0.2402 - val_accuracy: 0.9172\n",
      "51/51 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "test_recall = []\n",
    "test_f1 = []\n",
    "for i in range(1):\n",
    "\n",
    "    dataset_num = dataset_all.label.value_counts().min()\n",
    "    dataset_symptoms_negative = dataset_all[dataset_all['label']==0].sample(dataset_num)\n",
    "    dataset_symptoms_positive = dataset_all[dataset_all['label']==1].sample(dataset_num)\n",
    "    dataset_symptoms = pd.concat([dataset_symptoms_negative, dataset_symptoms_positive])\n",
    "    \n",
    "    X = dataset_symptoms.iloc[:,:-1]\n",
    "    y = dataset_symptoms.iloc[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "    # Create sequential model \n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    #Dense layer as first layer\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.keras.layers.ReLU(), input_shape=(187,)))\n",
    "\n",
    "    #Dense layer as second layer\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.keras.layers.ReLU()))\n",
    "\n",
    "    #Dense layer as third layer\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.keras.layers.ReLU()))\n",
    "\n",
    "    #Dense layer as fourth layer\n",
    "    model.add(tf.keras.layers.Dense(64, activation=tf.keras.layers.ReLU()))\n",
    "\n",
    "    #Softmax as last layer with two outputs\n",
    "    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    ann_model_history = model.fit(X_train, y_train, epochs=1000, batch_size = 256, validation_data = (X_test, y_test))\n",
    "\n",
    "    y_pred1 = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred1, axis=1)\n",
    "\n",
    "    # Print f1, precision, and recall scores\n",
    "    test_acc.append((accuracy_score(y_test, y_pred)))\n",
    "    test_recall.append((recall_score(y_test, y_pred)))\n",
    "    test_f1.append((f1_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the class probabilities\n",
    "# y_probs = model.predict(X_test)\n",
    "\n",
    "# # Select the class with the highest predicted probability as the positive class\n",
    "# y_probs = y_probs[:,1]\n",
    "# y_test = y_test\n",
    "\n",
    "# # Calculate the ROC AUC score\n",
    "# roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "# # Plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "# plt.plot(fpr, tpr, label=\"ROC AUC: {:.3f}\".format(roc_auc))\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recall = pd.DataFrame(test_recall, columns=['test_recall'])\n",
    "\n",
    "test_f1 = pd.DataFrame(test_f1, columns = ['test_f1'])\n",
    "\n",
    "test_acc = pd.DataFrame(test_acc, columns=['test_acc'])\n",
    "\n",
    "all_events_lr = pd.concat([test_recall, test_f1, test_acc],axis=1)\n",
    "# all_events_lr.to_csv('n_evaluation_baseline_MLP.csv')\n",
    "all_events_lr.boxplot()  \n",
    "plt.ylim(0.8,1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict the probabilities of positive class\n",
    "# y_pred1 = model.predict(X_test)\n",
    "# y_pred = np.argmax(y_pred1, axis=1)\n",
    "\n",
    "# # Calculate the ROC AUC score\n",
    "# roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# # Plot the ROC curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "# plt.plot(fpr, tpr, label=\"ROC AUC: {:.3f}\".format(roc_auc))\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plot_metric.functions import BinaryClassification\n",
    "# # Visualisation with plot_metric\n",
    "# bc = BinaryClassification(y_test, y_pred, labels=[\"Class 1\", \"Class 2\"])\n",
    "\n",
    "# # Figures\n",
    "# plt.figure(figsize=(5,5))\n",
    "# bc.plot_roc_curve()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42db6f1feb5be9d95545c2a7b7395325c381e86fa288f14274020ac1bf67e557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
