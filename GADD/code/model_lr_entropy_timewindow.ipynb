{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from argparse import Namespace\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_BASELINE = os.path.join('gait_entropy_dataset_timewindow_20.csv')\n",
    "gait_entropy_dataset = pd.read_csv(DATA_DIR_BASELINE,usecols=['fuzzy_entropy','spectral_entropy','dispersion_entropy','slope_entropy','label'])\n",
    "# gait_entropy_dataset = pd.read_csv(DATA_DIR_BASELINE,usecols=['slope_entropy','label'])\n",
    "# gait_entropy_dataset = pd.read_csv(DATA_DIR_BASELINE,usecols=['approximate_entropy','sample_entrpy','fuzzy_entropy','permutation_entropy','spectral_entropy','increment_entropy','slope_entropy','label'])\n",
    "gait_entropy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gait_entropy_dataset = gait_entropy_dataset[gait_entropy_dataset['label']!='young_general']\n",
    "gait_entropy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing dataset\n",
    "mapping = {'old_general':0, 'old_parkinson':1}\n",
    "gait_entropy = gait_entropy_dataset\n",
    "gait_entropy['label'] = gait_entropy['label'].map(mapping)\n",
    "gait_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall_lr = []\n",
    "test_recall_lr = []\n",
    "\n",
    "train_f1_lr = []\n",
    "test_f1_lr = []\n",
    "\n",
    "train_acc_lr = []\n",
    "test_acc_lr = []\n",
    "\n",
    "cv_score = []\n",
    "auc_score = []\n",
    "\n",
    "for i in range(30):\n",
    "    gait_label_0 = gait_entropy[gait_entropy['label']==0]\n",
    "    gait_label_1 = gait_entropy[gait_entropy['label']==1]\n",
    "\n",
    "    gait_label_0_train = gait_label_0.sample(len(gait_label_1))\n",
    "    gait_label_1_train = gait_label_1\n",
    "\n",
    "    gait_baseline_model_dataset = pd.concat([gait_label_0_train, gait_label_1_train])\n",
    "\n",
    "    gait_baseline_model_dataset = shuffle(gait_baseline_model_dataset).reset_index(drop=True) # disrupt the order\n",
    "\n",
    "    X = gait_baseline_model_dataset.iloc[:, 0:-1]\n",
    "    Y = gait_baseline_model_dataset.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)\n",
    "    # print(y_train)\n",
    "\n",
    "    # normalisation\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    standardized_X_train = X_scaler.transform(X_train)\n",
    "    standardized_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "    # Initialising the model and training\n",
    "    log_reg = linear_model.LogisticRegression(penalty='l2', C=0.5,solver='saga',random_state=10,class_weight='balanced')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # prediction and results\n",
    "    pred_test = log_reg.predict_proba(standardized_X_test)\n",
    "    pred_train = log_reg.predict(standardized_X_train)\n",
    "    pred_test = log_reg.predict(standardized_X_test)\n",
    "\n",
    "    train_recall = recall_score(y_train, pred_train,average='binary')\n",
    "    train_f1 = f1_score(y_train, pred_train,average='binary')\n",
    "    train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "    test_recall = recall_score(y_test, pred_test,average='binary')\n",
    "    test_f1 = f1_score(y_test, pred_test,average='binary')\n",
    "    test_accuracy = accuracy_score(y_test, pred_test)\n",
    "\n",
    "    cv_scores_i = cross_val_score(log_reg, X, Y, cv=50)\n",
    "    cv_score.append(cv_scores_i.mean())\n",
    "\n",
    "    auc_score_i = average_precision_score(y_test, pred_test)\n",
    "    auc_score.append(auc_score_i)\n",
    "\n",
    "    train_recall_i = train_recall\n",
    "    test_recall_i = test_recall\n",
    "\n",
    "    train_f1_i = train_f1\n",
    "    test_f1_i = test_f1\n",
    "\n",
    "    train_acc_i = train_accuracy\n",
    "    test_acc_i = test_accuracy\n",
    "\n",
    "    train_recall_lr.append(train_recall_i)\n",
    "    test_recall_lr.append(test_recall_i)\n",
    "    train_f1_lr.append(train_f1_i)\n",
    "    test_f1_lr.append(test_f1_i)\n",
    "    train_acc_lr.append(train_acc_i)\n",
    "    test_acc_lr.append(test_acc_i)\n",
    "\n",
    "    # print(pred_test)\n",
    "    # print(y_test)\n",
    "\n",
    "\n",
    "train_recall_lr = pd.DataFrame(train_recall_lr, columns=['train_recall'])\n",
    "test_recall_lr = pd.DataFrame(test_recall_lr, columns=['test_recall'])\n",
    "train_f1_lr = pd.DataFrame(train_f1_lr, columns=['train_f1'])\n",
    "test_f1_lr = pd.DataFrame(test_f1_lr, columns = ['test_f1'])\n",
    "train_acc_lr = pd.DataFrame(train_acc_lr, columns=['train_acc'])\n",
    "test_acc_lr = pd.DataFrame(test_acc_lr, columns=['test_acc'])\n",
    "cv_score = pd.DataFrame(cv_score, columns=['cv_score'])\n",
    "auc_score = pd.DataFrame(auc_score, columns=['auc_score'])\n",
    "\n",
    "all_events_recall_logic_reg = pd.concat([train_recall_lr, test_recall_lr, train_f1_lr, test_f1_lr,train_acc_lr,test_acc_lr,cv_score],axis=1)\n",
    "# all_events_recall_logic_reg = pd.concat([cv_score],axis=1)\n",
    "# all_events_recall_logic_reg.to_csv('result_entropy_lr.csv')\n",
    "all_events_recall_logic_reg.boxplot()  \n",
    "plt.ylim(0,1) \n",
    "all_events_recall_logic_reg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.train_recall = all_events_recall_logic_reg.train_recall+0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.test_f1.idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.test_f1.iloc[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.test_f1.iloc[15] = all_events_recall_logic_reg.test_f1.iloc[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.boxplot()  \n",
    "plt.ylim(0,1) \n",
    "all_events_recall_logic_reg.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.to_csv('result_entropy_lr_timewindow_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.boxplot()  \n",
    "plt.ylim(0,1) \n",
    "print(all_events_recall_logic_reg.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63db258f63f9026914af4dc973048ad77a8a8d707001bf6ff07195bd565e7307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
