{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.utils import shuffle\n",
    "from argparse import Namespace\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_BASELINE = os.path.join('gait_baseline_dataset_timewindow_20.csv')\n",
    "gait_baseline_dataset = pd.read_csv(DATA_DIR_BASELINE, usecols=['gait_avg','gait_cv','gait_stdfd','label'])\n",
    "gait_baseline_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_parkinson = gait_baseline_dataset[gait_baseline_dataset['label']=='old_parkinson']\n",
    "# gait_baseline_dataset = pd.concat([gait_baseline_dataset,add_parkinson])\n",
    "# gait_baseline_dataset\n",
    "\n",
    "gait_baseline_dataset = gait_baseline_dataset[gait_baseline_dataset['label']!='young_general']\n",
    "# gait_baseline_dataset = pd.concat([gait_baseline_dataset,gait_baseline_dataset])\n",
    "gait_baseline_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing dataset\n",
    "# mapping = {'young_general':0, 'old_general':0, 'old_parkinson':1}\n",
    "# gait_baseline = gait_baseline_dataset\n",
    "# gait_baseline['label'] = gait_baseline['label'].map(mapping)\n",
    "# gait_baseline\n",
    "\n",
    "mapping = {'old_general':0, 'old_parkinson':1}\n",
    "gait_baseline = gait_baseline_dataset\n",
    "gait_baseline['label'] = gait_baseline['label'].map(mapping)\n",
    "gait_baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_recall_lr = []\n",
    "# test_recall_lr = []\n",
    "\n",
    "# train_f1_lr = []\n",
    "# test_f1_lr = []\n",
    "\n",
    "# train_acc_lr = []\n",
    "# test_acc_lr = []\n",
    "\n",
    "# for i in range(30):\n",
    "#     # gait_label_0 = gait_baseline[gait_baseline['label']==0]\n",
    "#     # gait_label_1 = gait_baseline[gait_baseline['label']==1]\n",
    "#     # gait_label_2 = gait_baseline[gait_baseline['label']==2]\n",
    "\n",
    "#     # gait_label_0_train = gait_label_0.sample(3)\n",
    "#     # gait_label_1_train = gait_label_1.sample(3)\n",
    "#     # gait_label_2_train = gait_label_2.sample(3)\n",
    "\n",
    "#     # gait_label_0_test = pd.concat([gait_label_0,gait_label_0_train])[~pd.concat([gait_label_0,gait_label_0_train]).duplicated(subset=['gait_std','gait_cv','gait_stdfd','label'],keep=False)]\n",
    "#     # gait_label_1_test = pd.concat([gait_label_1,gait_label_1_train])[~pd.concat([gait_label_1,gait_label_1_train]).duplicated(subset=['gait_std','gait_cv','gait_stdfd','label'],keep=False)]\n",
    "#     # gait_label_2_test = pd.concat([gait_label_2,gait_label_2_train])[~pd.concat([gait_label_2,gait_label_2_train]).duplicated(subset=['gait_std','gait_cv','gait_stdfd','label'],keep=False)]\n",
    "\n",
    "\n",
    "#     # gait_baseline_train = pd.concat([gait_label_0_train, gait_label_1_train, gait_label_2_train])\n",
    "#     # gait_baseline_test = pd.concat([gait_label_0_test, gait_label_1_test, gait_label_2_test])\n",
    "\n",
    "#     # gait_baseline_train = shuffle(gait_baseline_train).reset_index(drop=True) # disrupt the order\n",
    "#     # gait_baseline_test = shuffle(gait_baseline_test).reset_index(drop=True) # disrupt the order\n",
    "\n",
    "\n",
    "#     # X_train = gait_baseline_train.iloc[:,0:3]\n",
    "#     # y_train = gait_baseline_train.iloc[:,-1]\n",
    "#     # X_test = gait_baseline_test.iloc[:,0:3]\n",
    "#     # y_test = gait_baseline_test.iloc[:,-1]\n",
    "\n",
    "#     gait_baseline = shuffle(gait_baseline).reset_index(drop=True) # disrupt the order\n",
    "#     X = gait_baseline.iloc[:, 0:3]\n",
    "#     Y = gait_baseline.iloc[:, -1]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.6, random_state=1234)\n",
    "\n",
    "#     # normalisation\n",
    "#     X_scaler = StandardScaler().fit(X_train)\n",
    "#     standardized_X_train = X_scaler.transform(X_train)\n",
    "#     standardized_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "#     # Initialising the model and training\n",
    "#     log_reg = linear_model.LogisticRegression(penalty='l2', C=0.1,solver='sag', max_iter=100, class_weight = 'balanced',random_state=10)\n",
    "#     log_reg.fit(X_train, y_train)\n",
    "\n",
    "#     # prediction and results\n",
    "#     pred_test = log_reg.predict_proba(standardized_X_test)\n",
    "#     pred_train = log_reg.predict(standardized_X_train)\n",
    "#     pred_test = log_reg.predict(standardized_X_test)\n",
    "\n",
    "#     train_recall = recall_score(y_train, pred_train,average='binary')\n",
    "#     train_f1 = f1_score(y_train, pred_train,average='binary')\n",
    "#     train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "#     test_recall = recall_score(y_test, pred_test,average='binary')\n",
    "#     test_f1 = f1_score(y_test, pred_test,average='binary')\n",
    "#     test_accuracy = accuracy_score(y_test, pred_test)\n",
    "\n",
    "#     train_recall_i = train_recall\n",
    "#     test_recall_i = test_recall\n",
    "\n",
    "#     train_f1_i = train_f1\n",
    "#     test_f1_i = test_f1\n",
    "\n",
    "#     train_acc_i = train_accuracy\n",
    "#     test_acc_i = test_accuracy\n",
    "\n",
    "#     train_recall_lr.append(train_recall_i)\n",
    "#     test_recall_lr.append(test_recall_i)\n",
    "#     train_f1_lr.append(train_f1_i)\n",
    "#     test_f1_lr.append(test_f1_i)\n",
    "#     train_acc_lr.append(train_acc_i)\n",
    "#     test_acc_lr.append(test_acc_i)\n",
    "\n",
    "# train_recall_lr = pd.DataFrame(train_recall_lr, columns=['train_recall'])\n",
    "# test_recall_lr = pd.DataFrame(test_recall_lr, columns=['test_recall'])\n",
    "# train_f1_lr = pd.DataFrame(train_f1_lr, columns=['train_f1'])\n",
    "# test_f1_lr = pd.DataFrame(test_f1_lr, columns = ['test_f1'])\n",
    "# train_acc_lr = pd.DataFrame(train_acc_lr, columns=['train_acc'])\n",
    "# test_acc_lr = pd.DataFrame(test_acc_lr, columns=['train_acc'])\n",
    "\n",
    "# all_events_recall_logic_reg = pd.concat([train_recall_lr, test_recall_lr, train_f1_lr, test_f1_lr,train_acc_lr,test_acc_lr],axis=1)\n",
    "# # all_events_recall_logic_reg.to_csv('all_events_recall_logic_reg.csv')\n",
    "# all_events_recall_logic_reg.boxplot()  \n",
    "# plt.ylim(0,1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall_lr = []\n",
    "test_recall_lr = []\n",
    "\n",
    "train_f1_lr = []\n",
    "test_f1_lr = []\n",
    "\n",
    "train_acc_lr = []\n",
    "test_acc_lr = []\n",
    "\n",
    "cv_score = []\n",
    "auc_score = []\n",
    "\n",
    "for i in range(30):\n",
    "    gait_label_0 = gait_baseline[gait_baseline['label']==0]\n",
    "    gait_label_1 = gait_baseline[gait_baseline['label']==1]\n",
    "\n",
    "    gait_label_0_train = gait_label_0.sample(len(gait_label_1))\n",
    "    gait_label_1_train = gait_label_1\n",
    "\n",
    "    gait_baseline_model_dataset = pd.concat([gait_label_0_train, gait_label_1_train])\n",
    "\n",
    "    gait_baseline_model_dataset = shuffle(gait_baseline_model_dataset).reset_index(drop=True) # disrupt the order\n",
    "\n",
    "    X = gait_baseline_model_dataset.iloc[:, 0:-1]\n",
    "    Y = gait_baseline_model_dataset.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)\n",
    "\n",
    "    # normalisation\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    standardized_X_train = X_scaler.transform(X_train)\n",
    "    standardized_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "    # Initialising the model and training\n",
    "    log_reg = linear_model.LogisticRegression(penalty='l2',C=0.9,solver='saga',random_state=10, class_weight='balanced')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # prediction and results\n",
    "    pred_test = log_reg.predict_proba(standardized_X_test)\n",
    "    pred_train = log_reg.predict(standardized_X_train)\n",
    "    pred_test = log_reg.predict(standardized_X_test)\n",
    "\n",
    "    train_recall = recall_score(y_train, pred_train,average='binary')\n",
    "    train_f1 = f1_score(y_train, pred_train,average='binary')\n",
    "    train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "    test_recall = recall_score(y_test, pred_test,average='binary')\n",
    "    test_f1 = f1_score(y_test, pred_test,average='binary')\n",
    "    test_accuracy = accuracy_score(y_test, pred_test)\n",
    "\n",
    "    train_recall_i = train_recall\n",
    "    test_recall_i = test_recall\n",
    "\n",
    "    train_f1_i = train_f1\n",
    "    test_f1_i = test_f1\n",
    "\n",
    "    train_acc_i = train_accuracy\n",
    "    test_acc_i = test_accuracy\n",
    "\n",
    "    train_recall_lr.append(train_recall_i)\n",
    "    test_recall_lr.append(test_recall_i)\n",
    "    train_f1_lr.append(train_f1_i)\n",
    "    test_f1_lr.append(test_f1_i)\n",
    "    train_acc_lr.append(train_acc_i)\n",
    "    test_acc_lr.append(test_acc_i)\n",
    "\n",
    "    cv_scores_i = cross_val_score(log_reg, X, Y, cv=50)\n",
    "    cv_score.append(cv_scores_i.mean())\n",
    "\n",
    "    auc_score_i = average_precision_score(y_test, pred_test)\n",
    "    auc_score.append(auc_score_i)\n",
    "\n",
    "train_recall_lr = pd.DataFrame(train_recall_lr, columns=['train_recall'])\n",
    "test_recall_lr = pd.DataFrame(test_recall_lr, columns=['test_recall'])\n",
    "train_f1_lr = pd.DataFrame(train_f1_lr, columns=['train_f1'])\n",
    "test_f1_lr = pd.DataFrame(test_f1_lr, columns = ['test_f1'])\n",
    "train_acc_lr = pd.DataFrame(train_acc_lr, columns=['train_acc'])\n",
    "test_acc_lr = pd.DataFrame(test_acc_lr, columns=['test_acc'])\n",
    "cv_score = pd.DataFrame(cv_score, columns=['cv_score'])\n",
    "auc_score = pd.DataFrame(auc_score, columns=['auc_score'])\n",
    "all_events_recall_logic_reg = pd.concat([train_recall_lr, test_recall_lr, train_f1_lr, test_f1_lr,train_acc_lr,test_acc_lr,cv_score],axis=1)\n",
    "# all_events_recall_logic_reg = pd.concat([cv_score],axis=1)\n",
    "# all_events_recall_logic_reg.to_csv('result_baseline_lr.csv')\n",
    "all_events_recall_logic_reg.boxplot()  \n",
    "plt.ylim(0,1) \n",
    "print(all_events_recall_logic_reg.mean())\n",
    "print(len(gait_label_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.to_csv('result_baseline_lr_timewindow_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events_recall_logic_reg.boxplot()  \n",
    "plt.ylim(0,1) \n",
    "print(all_events_recall_logic_reg.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # gait_baseline = shuffle(gait_baseline).reset_index(drop=True) # disrupt the order\n",
    "# # X = gait_baseline.iloc[:, 0:3]\n",
    "# # Y = gait_baseline.iloc[:, -1]\n",
    "# # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)\n",
    "\n",
    "# X_train = gait_baseline_train.iloc[:,0:3]\n",
    "# y_train = gait_baseline_train.iloc[:,-1]\n",
    "# X_test = gait_baseline_test.iloc[:,0:3]\n",
    "# y_test = gait_baseline_test.iloc[:,-1]\n",
    "\n",
    "# # normalisation\n",
    "# X_scaler = StandardScaler().fit(X_train)\n",
    "# standardized_X_train = X_scaler.transform(X_train)\n",
    "# standardized_X_test = X_scaler.transform(X_test)\n",
    "\n",
    "# # Initialising the model and training\n",
    "# log_reg = linear_model.LogisticRegression(penalty='l2', C=0.1,solver='sag', max_iter=100, class_weight = 'balanced',random_state=10)\n",
    "# log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prediction and results\n",
    "# pred_test = log_reg.predict_proba(standardized_X_test)\n",
    "# pred_train = log_reg.predict(standardized_X_train)\n",
    "# pred_test = log_reg.predict(standardized_X_test)\n",
    "\n",
    "# train_recall = recall_score(y_train, pred_train,average='weighted')\n",
    "# train_f1 = f1_score(y_train, pred_train,average='weighted')\n",
    "# train_accuracy = accuracy_score(y_train, pred_train)\n",
    "\n",
    "# test_recall = recall_score(y_test, pred_test,average='weighted')\n",
    "# test_f1 = f1_score(y_test, pred_test,average='weighted')\n",
    "# test_accuracy = accuracy_score(y_test, pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('train_recall',train_recall)\n",
    "# print('test_recall',test_recall)\n",
    "# print('train_f1',train_f1)\n",
    "# print('test_f1',test_f1)\n",
    "# print('train_accuracy',train_accuracy)\n",
    "# print('test_accuracy',test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63db258f63f9026914af4dc973048ad77a8a8d707001bf6ff07195bd565e7307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
